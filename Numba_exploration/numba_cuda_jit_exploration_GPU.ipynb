{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed4684f-7b38-4e67-81e1-b79b40299ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b1faa0-d819-4418-bc26-6f7c23a8d9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max threads per block - 1024\n"
     ]
    }
   ],
   "source": [
    "##Some GPU metrics\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "\n",
    "print(f\"Max threads per block - {device.MAX_THREADS_PER_BLOCK}\") ##Work with this as this \n",
    "                                            #is required for locating idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609401a8-13d9-479e-ae4e-4e4a9bc38939",
   "metadata": {},
   "source": [
    "#### Basic 1st GPU kernel using cuda jit from numbba - Square tthe elements of array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb95ebe8-136a-4cb6-90f5-ae2aa263a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@cuda.jit\n",
    "def square_kernel(ip, op):\n",
    "    idx = cuda.grid(1) #ip is 1D\n",
    "\n",
    "    if idx < ip.size: ## bounds check\n",
    "        op[idx] = ip[idx] ** 2   ## Note that this is not a looping thing\n",
    "\n",
    "\n",
    "##Data on CPU\n",
    "ip = np.arange(1000000, dtype=np.int64)\n",
    "op = np.zeros_like(ip)\n",
    "\n",
    "##Copy data to GPU\n",
    "d_arr = cuda.to_device(ip)\n",
    "d_result = cuda.to_device(op)\n",
    "\n",
    "threads_per_block = 1024\n",
    "blocks_req = (ip.size + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "square_kernel[blocks_req, threads_per_block](d_arr, d_result)\n",
    "\n",
    "result = d_result.copy_to_host()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f0cf6cd-9735-42ed-9ed8-f78f1eace4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del  d_result, ip, op, result, d_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63015865-4946-41a6-b335-1c0ed7dcd6a0",
   "metadata": {},
   "source": [
    "#### Element-wise ops -start with addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c22dcea-a79b-4c71-a5d7-47a4700d4ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75598412 0.55791599 1.45630312 1.29798355 0.85802794 1.15188144\n",
      " 1.56718149 1.06770789 1.0787877  0.22737159]\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def add_arrays(a, b, arr_sum):\n",
    "    idx = cuda.grid(1)\n",
    "\n",
    "    if idx < arr_sum.size: ## this should probably do bounds check for all i/o\n",
    "        arr_sum[idx] = a[idx] + b[idx]\n",
    "\n",
    "\n",
    "##Create arrays on CPU\n",
    "ip1 = np.random.rand(1000000)\n",
    "ip2 = np.random.rand(1000000)\n",
    "\n",
    "#Given this is size check its easier to assert this on CPU itself\n",
    "assert ip1.size == ip2.size\n",
    "\n",
    "res = np.zeros_like(ip1)\n",
    "arr_sum = cuda.to_device(res)\n",
    "\n",
    "\n",
    "threads_per_block = 1024\n",
    "blocks = (ip1.size + threads_per_block - 1) // threads_per_block\n",
    "add_arrays[blocks, threads_per_block](cuda.to_device(ip1), \n",
    "                                      cuda.to_device(ip2),\n",
    "                                      arr_sum)\n",
    "\n",
    "\n",
    "print((arr_sum.copy_to_host()[:10]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b67fbb7-d34f-47a8-a7f7-17f02857d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ip1, ip2, res, arr_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f2e2f9-bb34-414c-bf25-073a34566dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb4dafa-3e85-4cd1-940e-2507d6bc0cfd",
   "metadata": {},
   "source": [
    "##### 2 D matrix addition - This is a lot easier than reduction operations in cuda jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3fd3509-ca03-4b54-a339-5464982ac4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.20875687 1.14076146 0.61147126 0.4950164  1.40049219 1.02442292\n",
      " 0.93548755 0.81207144 0.75357317 1.48887563]\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit(fastmath=True)  ##allow fastmath\n",
    "def add_2d_matrices(A, B, C):\n",
    "\n",
    "    i,j = cuda.grid(2)\n",
    "\n",
    "    if i < A.shape[0] and j < A.shape[1]:\n",
    "        C[i,j] = A[i,j] + B[i,j]\n",
    "\n",
    "\n",
    "A = np.random.rand(1000, 1000)\n",
    "B = np.random.rand(1000, 1000)\n",
    "C = np.zeros_like(A)\n",
    "\n",
    "\n",
    "assert A.shape == B.shape \n",
    "\n",
    "threads_per_block = (32, 32)  ##32*32=1024\n",
    "blocks_x = (A.shape[0] + threads_per_block[0] - 1) // threads_per_block[0] # Blocks along 2 axes - #This is a visual illusion. In reality this doesnot exist \n",
    "blocks_y = (A.shape[1] + threads_per_block[1] - 1) // threads_per_block[1]\n",
    "\n",
    "res = cuda.to_device(C)\n",
    "\n",
    "add_2d_matrices[(blocks_x, blocks_y), threads_per_block](cuda.to_device(A),\n",
    "                                                        cuda.to_device(B),\n",
    "                                                        res)\n",
    "\n",
    "print(res.copy_to_host()[0][:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5de3c1c-3048-4719-b09d-9e89c7ed82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del A, B, C, res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f98f6d-bd86-471a-8a43-0a8d86b1588a",
   "metadata": {},
   "source": [
    "##### Reduction type operations - This felt a bit difficult to understand\n",
    "##### Honestly cupy is a lot more easier for this, if builtin ones are not helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b73b85-4235-4eba-967f-6d25d90b2920",
   "metadata": {},
   "source": [
    "##### Numba atomic operations - \n",
    "Usually used to prevent race conditions when you have want to read or write updates correctly. Mostly used when doing reduction type operations. Key tip is try to leverage shared memory to do this as opposed to global memory on GPU to facilitate faster read/write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ac5154c-5fc7-4846-8aa0-4de19960638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def sum_array(a, op):\n",
    "\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < a.size:\n",
    "        cuda.atomic.add(op, 0, a[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a5f70f-d0c8-4222-a6d5-d65dca20530d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500134.07440474]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.random(1000000).astype(np.float64)\n",
    "d_result = cuda.to_device(np.array([0.0], dtype=np.float64))\n",
    "\n",
    "tpb = 1024\n",
    "blocks = (a.size + tpb - 1) // tpb\n",
    "sum_array[blocks, tpb](cuda.to_device(a),d_result)\n",
    "print(d_result.copy_to_host())\n",
    "\n",
    "##Note play around with floats -> using float32 in the kernel and np.sum is internally\n",
    "##float64 and given that these are floats due to roudning you will get a different answer\n",
    "\n",
    "##In this example use float32 in kernel you will get a different answer with a larg diffewrnce with np.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3273ea67-0c3d-42a9-9e72-d7709b0fe28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(500134.07440474763)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c019089-4171-406a-8fca-142bee60d0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9e7ac-350c-412e-8ffa-159789444105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-programming-for-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
