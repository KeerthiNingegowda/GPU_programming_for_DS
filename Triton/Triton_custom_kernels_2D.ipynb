{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238d22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b088f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Matrix addition - Note ask AI to teach you about the math behind working out block indices\n",
    "#it is a lot more easier to do that\n",
    "\n",
    "@triton.jit\n",
    "def add_two_matrices(x_ptr, y_ptr, op_ptr, n_rows, n_cols, BLOCK_SIZE_X:tl.constexpr, BLOCK_SIZE_Y:tl.constexpr):\n",
    "\n",
    "    pid_x = tl.program_id(0)\n",
    "    pid_y = tl.program_id(1)\n",
    "\n",
    "    ##This is simple because x and y are supposed to have the same shape\n",
    "    row_offsets = pid_x * BLOCK_SIZE_X + tl.arange(0, BLOCK_SIZE_X)\n",
    "    col_offsets = pid_y * BLOCK_SIZE_Y + tl.arange(0, BLOCK_SIZE_Y)\n",
    "\n",
    "    ##Final offset -> combine both of them because indices need to be flat for memory access\n",
    "    offsets = row_offsets[:,None] * n_cols + col_offsets[None,:]\n",
    "\n",
    "    #mask -\n",
    "    masks = (row_offsets[:,None] < n_rows) & (col_offsets[None,:] < n_cols)\n",
    "\n",
    "    x = tl.load(x_ptr+offsets, mask=masks)\n",
    "    y = tl.load(y_ptr+offsets, mask=masks)\n",
    "\n",
    "    z = x+y\n",
    "\n",
    "    tl.store(op_ptr+offsets, z, mask=masks)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5dd456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_matrix_add():\n",
    "    x = torch.ones(100,130, device=\"cuda\", dtype=torch.float32)\n",
    "    y = torch.ones(100,130, device=\"cuda\", dtype=torch.float32)\n",
    "    z = torch.zeros_like(x)\n",
    "\n",
    "    assert x.shape ==  y.shape\n",
    "    n_rows, n_cols = x.shape\n",
    "\n",
    "    grid = lambda meta : (\n",
    "        triton.cdiv(n_rows, meta[\"BLOCK_SIZE_X\"]),\n",
    "        triton.cdiv(n_cols, meta[\"BLOCK_SIZE_Y\"]))\n",
    "\n",
    "    add_two_matrices[grid](x,y,z,n_rows,n_cols,32,32)\n",
    "\n",
    "    ##Simple sanity check - Compute sum along rows and cols - This works only if all of them all identical\n",
    "    print(torch.sum(z, axis=0).unique())\n",
    "    print(torch.sum(z, axis=1).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9a63e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([200.], device='cuda:0')\n",
      "tensor([260.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "launch_matrix_add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fcbaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2D Copy Kernel using tile indexing only\n",
    "\n",
    "@triton.jit\n",
    "def matrix_copy_kernel(ip_ptr, op_ptr, n_rows, n_cols, BLOCK_SIZE_X:tl.constexpr, BLOCK_SIZE_Y:tl.constexpr):\n",
    "\n",
    "    pid_row = tl.program_id(0)\n",
    "    pid_col = tl.program_id(1)\n",
    "\n",
    "    #Offsets\n",
    "    row_offsets = pid_row * BLOCK_SIZE_X + tl.arange(0, BLOCK_SIZE_X)\n",
    "    col_offsets = pid_col * BLOCK_SIZE_Y + tl.arange(0, BLOCK_SIZE_Y)\n",
    "    offsets = row_offsets[:,None] * n_cols + col_offsets[None,:] ##Will get contiguous indices\n",
    "\n",
    "    #masks\n",
    "    mask = (row_offsets[:,None] < n_rows) & (col_offsets[None,:] < n_cols)\n",
    "\n",
    "    ip_mat = tl.load(ip_ptr+offsets, mask=mask)\n",
    "    op_mat = ip_mat\n",
    "\n",
    "    tl.store(op_ptr+offsets,op_mat,mask=mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cf1c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_copy_kernel():\n",
    "    x = torch.randn(157,123, device='cuda', dtype=torch.float32)\n",
    "    y = torch.zeros_like(x)\n",
    "\n",
    "    print(torch.equal(x,y))\n",
    "\n",
    "    n_rows, n_cols = x.shape\n",
    "    grid = lambda meta : (\n",
    "        triton.cdiv(n_rows, meta[\"BLOCK_SIZE_X\"]),\n",
    "        triton.cdiv(n_cols, meta[\"BLOCK_SIZE_Y\"])\n",
    "    )\n",
    "\n",
    "    matrix_copy_kernel[grid](x,y,n_rows,n_cols,32, 32)\n",
    "\n",
    "    print(torch.equal(x,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f75dca12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "launch_copy_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe7575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Row Scaling Kernel (Mixed 2D + 1D indexing) -> a[row,col] *= scale[row]\n",
    "##Kep in mind a = (M*N) scale = (M,), OP = (M,N);  i.e. This is elementwise scaling not\n",
    "##dot product. this is like multiply every row by \n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def row_scale_kernel(mat2d_ptr, scale_ptr, op_ptr, n_rows, n_cols,\n",
    "                    BLOCK_SIZE_ROW:tl.constexpr,\n",
    "                    BLOCK_SIZE_COL:tl.constexpr):\n",
    "\n",
    "    pid_row = tl.program_id(0)\n",
    "    pid_col = tl.program_id(1)\n",
    "    row_offsets = pid_row * BLOCK_SIZE_ROW + tl.arange(0, BLOCK_SIZE_ROW)\n",
    "    col_offsets = pid_col * BLOCK_SIZE_COL + tl.arange(0, BLOCK_SIZE_COL)\n",
    "    offsets = row_offsets[:,None] * n_cols + col_offsets[None,:]\n",
    "    masks = (row_offsets[:,None] < n_rows) & (col_offsets[None,:] < n_cols)\n",
    "\n",
    "    #scale vector mask\n",
    "    scale_mask = row_offsets < n_rows ##Reuse pid_row as the dimensions are same and makes sense at a block level\n",
    "\n",
    "    #Load the data\n",
    "    mat2d = tl.load(mat2d_ptr+offsets, mask=masks)\n",
    "    scale_vector = tl.load(scale_ptr+row_offsets, mask=scale_mask)\n",
    "\n",
    "    op = mat2d * scale_vector[:,None]\n",
    "\n",
    "    tl.store(op_ptr+offsets, op, mask=masks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1524d569-ce24-4840-948c-c68e93bdbed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_row_scale():\n",
    "\n",
    "    x = torch.randn(151,137, device=\"cuda\", dtype=torch.float32)\n",
    "    scale = torch.randn(151, device=\"cuda\", dtype=torch.float32)\n",
    "    y = torch.empty_like(x)\n",
    "\n",
    "    n_rows, n_cols = x.shape\n",
    "    grid = lambda meta : (\n",
    "        triton.cdiv(n_rows, meta[\"BLOCK_SIZE_ROW\"]),\n",
    "        triton.cdiv(n_cols, meta[\"BLOCK_SIZE_COL\"])\n",
    "    )\n",
    "\n",
    "    row_scale_kernel[grid](x, scale, y, n_rows, n_cols, BLOCK_SIZE_ROW=32, BLOCK_SIZE_COL=32)\n",
    "    print(torch.equal(x*scale[:,None],y)) ##Use allclose if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b57a43-e352-40b3-8df2-0b84ebb26352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "launch_row_scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e61d534-07f9-4fe0-9864-4a79e166790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Colum scaling kernel -> a[row,col ] *= scale[col]; multiply each column with a  particular value\n",
    "\n",
    "@triton.jit\n",
    "def column_scale_kernel(mat2d_ptr, scale_ptr, op_ptr, n_rows, n_cols, \n",
    "                       BLOCK_SIZE_ROW:tl.constexpr,\n",
    "                       BLOCK_SIZE_COL:tl.constexpr):\n",
    "\n",
    "    pid_row = tl.program_id(0)\n",
    "    pid_col = tl.program_id(1)\n",
    "\n",
    "    row_offsets = pid_row * BLOCK_SIZE_ROW + tl.arange(0, BLOCK_SIZE_ROW)\n",
    "    col_offsets = pid_col * BLOCK_SIZE_COL + tl.arange(0, BLOCK_SIZE_COL)\n",
    "    offsets = row_offsets[:, None] * n_cols + col_offsets[None,:]\n",
    "\n",
    "    masks = (row_offsets[:,None] < n_rows) & (col_offsets[None,:] < n_cols)\n",
    "\n",
    "    #Compute scalee masks\n",
    "    scale_mask = col_offsets < n_cols\n",
    "\n",
    "    mat2d_ip = tl.load(mat2d_ptr+offsets, mask=masks)\n",
    "    scalar = tl.load(scale_ptr+col_offsets, mask=scale_mask)\n",
    "\n",
    "    op = mat2d_ip * scalar[None,:]\n",
    "\n",
    "    tl.store(op_ptr+offsets, op, mask=masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28685de-1499-4e4c-b852-cfccef790130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_col_scale():\n",
    "\n",
    "    x = torch.randn(159,191, device=\"cuda\", dtype=torch.float32)\n",
    "    scalar = torch.randn(191, device=\"cuda\", dtype=torch.float32)\n",
    "    y = torch.empty_like(x)\n",
    "\n",
    "    n_rows, n_cols = x.shape\n",
    "    grid = lambda meta :(\n",
    "        triton.cdiv(n_rows, meta[\"BLOCK_SIZE_ROW\"]),\n",
    "        triton.cdiv(n_cols, meta[\"BLOCK_SIZE_COL\"])\n",
    "    )\n",
    "    column_scale_kernel[grid](x, scalar, y, n_rows, n_cols, BLOCK_SIZE_ROW=32,\n",
    "                              BLOCK_SIZE_COL=32)\n",
    "\n",
    "    print(torch.equal(x*scalar[None,:], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "318d6811-e412-4ebe-8e92-3d91b2eca92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "launch_col_scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a2683e0-fa5b-4448-b7ef-3ef7c7f8f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transpose of a matrix\n",
    "\n",
    "@triton.jit\n",
    "def transpose_kernel(ip_ptr, op_ptr, n_rows, n_cols, BLOCK_SIZE_ROW:tl.constexpr,\n",
    "                    BLOCK_SIZE_COL:tl.constexpr):\n",
    "\n",
    "    pid_row = tl.program_id(0)\n",
    "    pid_col = tl.program_id(1)\n",
    "\n",
    "    row_offsets = pid_row * BLOCK_SIZE_ROW + tl.arange(0, BLOCK_SIZE_ROW)\n",
    "    col_offsets = pid_col * BLOCK_SIZE_COL + tl.arange(0, BLOCK_SIZE_COL)\n",
    "    load_offsets = row_offsets[:,None] * n_cols + col_offsets[None,:]\n",
    "    \n",
    "    load_masks = (row_offsets[:,None] < n_rows) & (col_offsets[None,:] < n_cols)\n",
    "\n",
    "    ip_matr = tl.load(ip_ptr+load_offsets, mask=load_masks)\n",
    "    op_matr = tl.trans(ip_matr)\n",
    "\n",
    "    store_offsets = col_offsets[:,None] * n_rows + row_offsets[None,:]\n",
    "    store_masks = (col_offsets[:,None]< n_cols) & (row_offsets[None,:] < n_rows)\n",
    "\n",
    "    tl.store(op_ptr+store_offsets, op_matr, mask=store_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f86c2096-31d0-4b0a-81fe-93b22181fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_transpose_kernel():\n",
    "\n",
    "    X = torch.randn(157,231, device=\"cuda\",dtype=torch.float32)\n",
    "    n_rows, n_cols = X.shape\n",
    "    X_transpose = torch.empty((n_cols, n_rows), device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "    grid = lambda meta : (\n",
    "        triton.cdiv(n_rows,meta[\"BLOCK_SIZE_ROW\"]),\n",
    "        triton.cdiv(n_cols, meta[\"BLOCK_SIZE_COL\"])\n",
    "    )\n",
    "\n",
    "    transpose_kernel[grid](X, X_transpose, n_rows, n_cols, 32,32)\n",
    "    # print(X)\n",
    "    # print(X_transpose)\n",
    "    print(torch.equal(X.T, X_transpose))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21dc0f88-d2a1-4b48-adc5-afde02fa5c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "launch_transpose_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a695edd-cbdc-4c63-9214-ed7f872388b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Masked Tile Write - Only copy data that satisfy conditioon (row_index + col_index)%2=0\n",
    "#Note A and B will already have values, you need to copy values from A where the above condition\n",
    "#is satisfied. \n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def masked_tile_write_kernel(ip1_ptr, ip2_ptr, n_rows, n_cols, BLOCK_SIZE_ROW:tl.constexpr,\n",
    "                            BLOCK_SIZE_COL:tl.constexpr):\n",
    "\n",
    "    pid_row = tl.program_id(0)\n",
    "    pid_col = tl.program_id(1)\n",
    "\n",
    "    row_offsets = pid_row * BLOCK_SIZE_ROW + tl.arange(0, BLOCK_SIZE_ROW)\n",
    "    col_offsets = pid_col * BLOCK_SIZE_COL + tl.arange(0, BLOCK_SIZE_COL)\n",
    "    offsets = row_offsets[:,None] * n_cols + col_offsets[None,:]\n",
    "    \n",
    "    mask1 = (row_offsets[:,None] < n_rows) & (col_offsets[None,:] < n_cols)\n",
    "    ##Broadcasting works here as one of the dimensions is 1\n",
    "    cond_mask = (row_offsets[:,None] +  col_offsets[None,:]) %2 ==0\n",
    "    final_mask = mask1 & cond_mask\n",
    "\n",
    "    ip = tl.load(ip1_ptr+offsets, mask=mask1)\n",
    "\n",
    "    tl.store(ip2_ptr+offsets, ip, mask=final_mask)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d1cb18b-e2f6-4744-8cbc-303ee63d0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_masked_tile_correctness(a,b, b_orij):\n",
    "    for i in range(a.shape[0]):\n",
    "        for j in range(b.shape[1]):\n",
    "            if (i+j)%2 == 0:\n",
    "                assert a[i,j] == b[i,j]\n",
    "            else:\n",
    "                assert b_orij[i,j] == b[i,j]\n",
    "                \n",
    "    return \"Assertion passed\" #It will break if tthe values are not similar\n",
    "\n",
    "def launch_masked_tile_kernel():\n",
    "    a = torch.zeros(535,729, device=\"cuda\", dtype=torch.float32)\n",
    "    b = torch.ones(535,729, device=\"cuda\", dtype=torch.float32)\n",
    "    b_copy = b.clone().detach()\n",
    "\n",
    "    n_rows, n_cols = a.shape\n",
    "    grid = lambda meta : (\n",
    "        triton.cdiv(n_rows, meta[\"BLOCK_SIZE_ROW\"]),\n",
    "        triton.cdiv(n_cols, meta[\"BLOCK_SIZE_COL\"])\n",
    "    )\n",
    "    masked_tile_write_kernel[grid](a,b,n_rows,n_cols,32,32)\n",
    "    print(test_masked_tile_correctness(a,b,b_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "778b302c-67f1-4023-b731-a89e3b4ec1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assertion passed\n"
     ]
    }
   ],
   "source": [
    "launch_masked_tile_kernel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6051bd76-4d86-4b55-90c2-e15191216cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sub-matrix extraction; Extract from a bigger matrix\n",
    "#Note that the mental model here is the ips and opss are of different size. So the \n",
    "#focus in basing the grid on output \n",
    "\n",
    "@triton.jit\n",
    "def submatrix_extraction_kernel(A_ptr, B_ptr, nrows_A, ncols_A, r0, c0, op_rows,\n",
    "                               op_cols, BLOCK_SIZE_ROW:tl.constexpr, BLOCK_SIZE_COL:tl.constexpr):\n",
    "\n",
    "    pid_row = tl.program_id(0)\n",
    "    pid_col = tl.program_id(1)\n",
    "\n",
    "    op_row_offsets = pid_row * BLOCK_SIZE_ROW + tl.arange(0, BLOCK_SIZE_ROW)\n",
    "    op_col_offsets = pid_col * BLOCK_SIZE_COL + tl.arange(0, BLOCK_SIZE_COL)\n",
    "    op_offsets = op_row_offsets[:,None] * op_cols + op_col_offsets[None,:]\n",
    "\n",
    "    #Probably there should be only one mask?\n",
    "    op_mask = (op_row_offsets[:,None] < op_rows) & (op_col_offsets[None,:] < op_cols)\n",
    "\n",
    "    #ip offsets \n",
    "    ip_row_offsets = r0 + op_row_offsets\n",
    "    ip_col_offsets = c0 + op_col_offsets\n",
    "    ip_offsets = ip_row_offsets[:,None] * ncols_A + ip_col_offsets[None,:]\n",
    " \n",
    "    A = tl.load(A_ptr+ip_offsets, mask=op_mask)\n",
    "    tl.store(B_ptr+op_offsets, A, mask=op_mask)\n",
    "    \n",
    "\n",
    "##Note checked with GPT - What I have for mask for tl.load is fine. However, it is also\n",
    "#important to make sure be on the defensive and add a safety mechanism\n",
    "#ip_mask = (ip_row_offsets[:,None]<nrows_A) & (ip_row_offsets[None,:]<ncols_A)\n",
    "#final_mask = ip_mask & op_mask \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "650f3e37-7c64-478c-83d0-89022f62585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_submatrix_kernel():\n",
    "    A = torch.randn(235,569, device=\"cuda\", dtype=torch.float32)\n",
    "    nrows_A, ncols_A = A.shape\n",
    "    op_rows, op_cols = (21,31)\n",
    "    r0,c0 = (151,323)\n",
    "\n",
    "    B = torch.zeros(op_rows,op_cols, device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "    grid = lambda meta : (\n",
    "        triton.cdiv(op_rows, meta[\"BLOCK_SIZE_ROW\"]),\n",
    "        triton.cdiv(op_cols, meta[\"BLOCK_SIZE_COL\"])\n",
    "    )\n",
    "\n",
    "    submatrix_extraction_kernel[grid](A, B, nrows_A, ncols_A, r0, c0, op_rows, op_cols, 32,32)\n",
    "    print(torch.equal(A[r0:r0+op_rows, c0:c0+op_cols],B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3ea27f3-df08-474d-b6f0-32760a760121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "launch_submatrix_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049de369-5cdf-4732-acd1-84f2f858f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
